{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-UBQLWIjGYNzAjRl7lldd-qQhpuTt3ZX","timestamp":1698679297326},{"file_id":"1g-Yt2Cj6PFLYY4jylSgPsRMp-150uUQB","timestamp":1697590469430}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"t2hPDx3Tvh0v"},"source":["# Homework 6\n","\n","In this homework you will be training and using a \"char-RNN\". This is the name given to a character-level recurrent neural network language model by [this famous blog post by Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Before you start on the rest of the homework, please give the blog post a read, it's quite good!\n","\n","I don't expect you to implement the char-RNN from scratch. Andrej's original char-rnn is in Torch (the predecessor to PyTorch that is not commonly used anymore). Fortunately, there are many other implementations of this model available; for example, there is one (in both mxnet and pytorch) in chapters 8 and 9 of [the textbook](http://d2l.ai), and another pytorch one [here](https://github.com/spro/char-rnn.pytorch). **Please use one of these example implementations (or another one that you find) when completing this homework**.\n","\n","For this homework, please complete the following steps:\n","\n","1. Download and tokenize the [Shakespeare dataset](http://www.gutenberg.org/files/100/100-0.txt) at a character level. I recommend basing your solution on the following code:\n","```Python\n","# Remove non-alphabetical characters, lowercase, and replace whitespace with ' '\n","raw_dataset = ' '.join(re.sub('[^A-Za-z ]+', '', text).lower().split())\n","# Maps token index to character\n","idx_to_char = list(set(raw_dataset))\n","# Maps character to token index\n","char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n","# Tokenize the dataset\n","corpus_indices = [char_to_idx[char] for char in raw_dataset]\n","```\n","1. Train a \"vanilla\" RNN (as described in chapter 9 of [the textbook](http://d2l.ai)) on the Shakespeare dataset. Report the training loss and generate some samples from the model at the end of training.\n","1. Train a GRU RNN (as described in chapter 10 of [the textbook](http://d2l.ai)) on the Shakespeare datatset. Is the final training loss higher or lower than the vanilla RNN? Are the samples from the model more or less realistic?\n","1. Find a smaller, simpler dataset than the Shakespeare data (you can find some ideas in Andrej's blog post, but feel free to get creative!) and train either the vanilla or GRU RNN on it instead. Is the final training loss higher or lower than it was for the Shakespeare data?"]},{"cell_type":"markdown","source":["1) data is tokenized on following cells steps (2-4)"],"metadata":{"id":"qv3huf0phmaf"}},{"cell_type":"code","source":["!pip install Unidecode"],"metadata":{"id":"1SpZVwqaAME4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698816316775,"user_tz":240,"elapsed":3742,"user":{"displayName":"João Dick","userId":"09906120919510529946"}},"outputId":"9e4deb54-1895-40cf-e572-6e4ed6950d28"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Unidecode in /usr/local/lib/python3.10/dist-packages (1.3.7)\n"]}]},{"cell_type":"markdown","source":["imports"],"metadata":{"id":"DM4jS3Zw_qm0"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import unidecode\n","import string\n","import random\n","import time\n","import math\n","import os\n","import argparse\n","import requests\n","from tqdm import tqdm"],"metadata":{"id":"OFPP04TL_k5a","executionInfo":{"status":"ok","timestamp":1698816318760,"user_tz":240,"elapsed":3,"user":{"displayName":"João Dick","userId":"09906120919510529946"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"XQ57XQBjO6jj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698816335296,"user_tz":240,"elapsed":15560,"user":{"displayName":"João Dick","userId":"09906120919510529946"}},"outputId":"b38eaf02-d7c1-43e0-d451-bd73aeb1e8bc"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["2) Vanilla RNN trained on Shakespeare ([source](https://github.com/vnikme/char-rnn.pytorch/tree/master))"],"metadata":{"id":"8GvrBrYV8GfL"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","class CharRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n","        super(CharRNN, self).__init__()\n","        self.model = model.lower()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","\n","        self.encoder = nn.Embedding(input_size, hidden_size)\n","        if self.model == \"gru\":\n","            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True)\n","        elif self.model == \"lstm\":\n","            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden):\n","        \"\"\"\n","            input: shape=(batch_size, seq_size)\n","            output: shape=(batch_size, seq_size, output_size)\n","        \"\"\"\n","        encoded = self.encoder(input)\n","        output, hidden = self.rnn(encoded, hidden)\n","        output = self.decoder(output)\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size, cuda):\n","        cuda_wrapper = lambda x: x.cuda() if cuda else x\n","        if self.model == \"lstm\":\n","            return (cuda_wrapper(Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))),\n","                    cuda_wrapper(Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))))\n","        return cuda_wrapper(Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))"],"metadata":{"id":"V8oeShgYcTS4","executionInfo":{"status":"ok","timestamp":1698818070026,"user_tz":240,"elapsed":204,"user":{"displayName":"João Dick","userId":"09906120919510529946"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import string\n","import random\n","import time\n","import math\n","\n","def read_file(filename):\n","    file = open(filename).read()\n","    all_characters = list(set(file))\n","    return file, len(file), all_characters, len(all_characters)\n","\n","# Turning a string into a tensor\n","\n","def char_tensor(string, all_characters):\n","    tensor = torch.zeros(len(string)).long()\n","    for c in range(len(string)):\n","        try:\n","            tensor[c] = all_characters.index(string[c])\n","        except:\n","            continue\n","    return tensor\n","\n","# Readable time elapsed\n","\n","def time_since(since):\n","    s = time.time() - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"metadata":{"id":"NxqOLlibcYI2","executionInfo":{"status":"ok","timestamp":1698818117657,"user_tz":240,"elapsed":4,"user":{"displayName":"João Dick","userId":"09906120919510529946"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","import os\n","import argparse\n","\n","def generate(decoder, all_characters, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n","    hidden = decoder.init_hidden(1, cuda)\n","    prime_input = Variable(char_tensor(prime_str, all_characters).unsqueeze(0))\n","\n","    if cuda:\n","        prime_input = prime_input.cuda()\n","    predicted = prime_str\n","\n","    # Use priming string to \"build up\" hidden state\n","    _, hidden = decoder(prime_input, hidden)\n","    inp = prime_input[0,-1].view(1, -1)\n","\n","    for p in range(predict_len):\n","        output, hidden = decoder(inp, hidden)\n","\n","        # Sample from the network as a multinomial distribution\n","        output_dist = output.data.view(-1).div(temperature).exp()\n","        top_i = torch.multinomial(output_dist, 1)[0]\n","\n","        # Add predicted character to string and use as next input\n","        predicted_char = all_characters[top_i]\n","        predicted += predicted_char\n","        inp = Variable(char_tensor(predicted_char, all_characters).unsqueeze(0))\n","        if cuda:\n","            inp = inp.cuda()\n","\n","    return predicted"],"metadata":{"id":"1_3h_rp3cfpw","executionInfo":{"status":"ok","timestamp":1698818138934,"user_tz":240,"elapsed":187,"user":{"displayName":"João Dick","userId":"09906120919510529946"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["filename = '/content/drive/MyDrive/CS2516/Homework/shakespeare.txt'\n","model = 'lstm'\n","n_epochs = 2000\n","print_every = 100\n","hidden_size = 128\n","n_layers = 2\n","learning_rate = 0.01\n","chunk_len = 200\n","batch_size = 128\n","shuffle = True\n","cuda = True\n","\n","if cuda:\n","    print(\"Using CUDA\")\n","\n","file, file_len, all_characters, n_characters = read_file(filename)\n","\n","def random_training_set(chunk_len, batch_size):\n","    inp = torch.LongTensor(batch_size, chunk_len)\n","    target = torch.LongTensor(batch_size, chunk_len)\n","    for bi in range(batch_size):\n","        start_index = random.randint(0, file_len - chunk_len - 1)\n","        end_index = start_index + chunk_len + 1\n","        chunk = file[start_index:end_index]\n","        inp[bi] = char_tensor(chunk[:-1], all_characters)\n","        target[bi] = char_tensor(chunk[1:], all_characters)\n","    inp = Variable(inp)\n","    target = Variable(target)\n","    if cuda:\n","        inp = inp.cuda()\n","        target = target.cuda()\n","    return inp, target\n","\n","def train(inp, target):\n","    \"\"\"\n","        inp: (batch_size, seq_size)\n","        target: (batch_size, seq_size)\n","    \"\"\"\n","    hidden = decoder.init_hidden(batch_size, cuda)\n","    decoder.zero_grad()\n","\n","    output, hidden = decoder(inp, hidden)\n","    loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n","\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.item()\n","\n","def save():\n","    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n","    torch.save((all_characters, decoder), save_filename)\n","    print('Saved as %s' % save_filename)\n","\n","# Initialize models and start training\n","\n","decoder = CharRNN(\n","    n_characters,\n","    hidden_size,\n","    n_characters,\n","    model=model,\n","    n_layers=n_layers,\n",")\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","if cuda:\n","    decoder.cuda()\n","\n","start = time.time()\n","all_losses = []\n","loss_avg = 0\n","\n","try:\n","    print(\"Training for %d epochs...\" % n_epochs)\n","    for epoch in tqdm(range(1, n_epochs + 1)):\n","        loss = train(*random_training_set(chunk_len, batch_size))\n","        loss_avg += loss\n","\n","        if epoch % print_every == 0:\n","            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","            print(generate(decoder, all_characters, 'Wh', 100, cuda=cuda), '\\n')\n","\n","    print(\"Saving...\")\n","    save()\n","\n","except KeyboardInterrupt:\n","    print(\"Saving before quit...\")\n","    save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uaDPS1ZbiYyy","executionInfo":{"status":"ok","timestamp":1698820083412,"user_tz":240,"elapsed":501193,"user":{"displayName":"João Dick","userId":"09906120919510529946"}},"outputId":"ee47908b-9385-4836-c1f6-5b64cde86068"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA\n","Training for 2000 epochs...\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 100/2000 [00:25<08:24,  3.77it/s]"]},{"output_type":"stream","name":"stdout","text":["[0m 25s (100 5%) 1.7850]\n","Wh semple the maid, in.\n","\n","MENIUS:\n","And his king of 'tide to verdel's grumpet,\n","But prick you, to parged i \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 200/2000 [00:50<08:16,  3.63it/s]"]},{"output_type":"stream","name":"stdout","text":["[0m 50s (200 10%) 1.5559]\n","When, by that the male or meat:\n","The good:\n","let a kiships the ruins he made the might ture and earred bu \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 300/2000 [01:15<07:22,  3.84it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 15s (300 15%) 1.4857]\n","Where, my bring out as where the sent was my antwart; but thou whom'd to her with a speak.\n","\n","CORIOLANUS \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 400/2000 [01:39<06:55,  3.85it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 39s (400 20%) 1.4015]\n","Where, go,--\n","And lose us uncle body is the sigod such execute.\n","\n","LEONTES:\n","Is now! is haste thou art not \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 500/2000 [02:04<06:36,  3.79it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 4s (500 25%) 1.3561]\n","Wherver in him. Can we shall finded thou hast\n","And his brother of time to see me prevered along for the \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 600/2000 [02:30<06:14,  3.74it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 29s (600 30%) 1.3669]\n","Wherefore come beching great thy lovy my blood\n","Hath dip of his father knonge of this slands\n","Of the mis \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 700/2000 [02:54<05:42,  3.80it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 54s (700 35%) 1.3398]\n","Where thee, by that effemies up an our mistress.\n","\n","PAULINA:\n","My father fellow,\n","And then afed men hands s \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 800/2000 [03:19<05:14,  3.81it/s]"]},{"output_type":"stream","name":"stdout","text":["[3m 19s (800 40%) 1.3436]\n","Where is dew the bloody of your grace.\n","\n","KING HENRY VI:\n","And, most for this corry that thou shame with G \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 900/2000 [03:45<04:58,  3.68it/s]"]},{"output_type":"stream","name":"stdout","text":["[3m 45s (900 45%) 1.2883]\n","Where suit and have appearth they ray:\n","Be assimy of the notes, here a\n","make with this hand of manteling \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 1000/2000 [04:10<04:37,  3.61it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 10s (1000 50%) 1.3118]\n","Where is in all the good de cousins bark.\n","If they do now do you swear\n","I says that talk of true, we we  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 1100/2000 [04:34<04:00,  3.74it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 34s (1100 55%) 1.2891]\n","Wheevein it say, how would I do once as will then cover\n","While you well then bold withal;\n","And tell me,  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 1200/2000 [05:00<03:46,  3.54it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 59s (1200 60%) 1.3051]\n","Wheretimes not warrant, Aufidius,\n","Do from my ears steal at this work.\n","\n","GRUMIO:\n","Heavion thou wast mine  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 1300/2000 [05:25<03:10,  3.68it/s]"]},{"output_type":"stream","name":"stdout","text":["[5m 25s (1300 65%) 1.2936]\n","Where was a man with me and a complot:\n","Since thy house and puttiful with vain;\n","For they still fearful, \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 1400/2000 [05:50<02:37,  3.80it/s]"]},{"output_type":"stream","name":"stdout","text":["[5m 50s (1400 70%) 1.2679]\n","Where is to paper mayor else his hand.\n","\n","ISABELLA:\n","Can past thou think thou holy and bear\n","The time in o \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 1500/2000 [06:15<02:16,  3.66it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 15s (1500 75%) 1.2806]\n","Where they are some own valiant that bearing him:\n","As I am no ashan they would be condain of the proud\n"," \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 1600/2000 [06:40<01:47,  3.72it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 40s (1600 80%) 1.2508]\n","Wheel you stay to help to an incanch;\n","The only flouring and create my sovereign.\n","I, where is struck an \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 1700/2000 [07:05<01:17,  3.85it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 5s (1700 85%) 1.2557]\n","Where is my womb, and you have been thou hast\n","viscent to friend and the world,\n","Which that I maid battl \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 1800/2000 [07:30<00:54,  3.69it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 30s (1800 90%) 1.2686]\n","Where is a merciful up.\n","\n","SICINIUS:\n","No, boy!\n","\n","Lord:\n","Let me be the gates to the bear\n","To slaughter'd hope \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 1900/2000 [07:55<00:28,  3.55it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 55s (1900 95%) 1.2576]\n","Where it be done: but that hitles may be executed,\n","And with him do will strive, become in it.\n","\n","DUKE VI \n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [08:20<00:00,  3.99it/s]"]},{"output_type":"stream","name":"stdout","text":["[8m 20s (2000 100%) 1.2537]\n","Where have I have no more before I\n","Was neglicians, and to my love the flierful devil\n","To the Thrance an \n","\n","Saving...\n","Saved as shakespeare.pt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["final loss:\n","\n","`1.2537`\n","\n","Final generated sequence:\n","\n","`Where have I have no more before I\n","Was neglicians, and to my love the flierful devil\n","To the Thrance an`"],"metadata":{"id":"u5XvaCHOkgIo"}},{"cell_type":"markdown","source":["3) GRU RNN trained on Shakespeare([source](https://github.com/vnikme/char-rnn.pytorch/tree/master))"],"metadata":{"id":"Hq-HXW-0av1O"}},{"cell_type":"code","source":["\n","filename = '/content/drive/MyDrive/CS2516/Homework/shakespeare.txt'\n","model = 'gru'\n","n_epochs = 2000\n","print_every = 100\n","hidden_size = 128\n","n_layers = 2\n","learning_rate = 0.01\n","chunk_len = 200\n","batch_size = 128\n","shuffle = True\n","cuda = True\n","\n","if cuda:\n","    print(\"Using CUDA\")\n","\n","file, file_len, all_characters, n_characters = read_file(filename)\n","\n","def random_training_set(chunk_len, batch_size):\n","    inp = torch.LongTensor(batch_size, chunk_len)\n","    target = torch.LongTensor(batch_size, chunk_len)\n","    for bi in range(batch_size):\n","        start_index = random.randint(0, file_len - chunk_len - 1)\n","        end_index = start_index + chunk_len + 1\n","        chunk = file[start_index:end_index]\n","        inp[bi] = char_tensor(chunk[:-1], all_characters)\n","        target[bi] = char_tensor(chunk[1:], all_characters)\n","    inp = Variable(inp)\n","    target = Variable(target)\n","    if cuda:\n","        inp = inp.cuda()\n","        target = target.cuda()\n","    return inp, target\n","\n","def train(inp, target):\n","    \"\"\"\n","        inp: (batch_size, seq_size)\n","        target: (batch_size, seq_size)\n","    \"\"\"\n","    hidden = decoder.init_hidden(batch_size, cuda)\n","    decoder.zero_grad()\n","\n","    output, hidden = decoder(inp, hidden)\n","    loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n","\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.item()\n","\n","def save():\n","    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n","    torch.save((all_characters, decoder), save_filename)\n","    print('Saved as %s' % save_filename)\n","\n","# Initialize models and start training\n","\n","decoder = CharRNN(\n","    n_characters,\n","    hidden_size,\n","    n_characters,\n","    model=model,\n","    n_layers=n_layers,\n",")\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","if cuda:\n","    decoder.cuda()\n","\n","start = time.time()\n","all_losses = []\n","loss_avg = 0\n","\n","try:\n","    print(\"Training for %d epochs...\" % n_epochs)\n","    for epoch in tqdm(range(1, n_epochs + 1)):\n","        loss = train(*random_training_set(chunk_len, batch_size))\n","        loss_avg += loss\n","\n","        if epoch % print_every == 0:\n","            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","            print(generate(decoder, all_characters, 'Wh', 100, cuda=cuda), '\\n')\n","\n","    print(\"Saving...\")\n","    save()\n","\n","except KeyboardInterrupt:\n","    print(\"Saving before quit...\")\n","    save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_hq04eTDclPY","executionInfo":{"status":"ok","timestamp":1698818862781,"user_tz":240,"elapsed":487107,"user":{"displayName":"João Dick","userId":"09906120919510529946"}},"outputId":"325ebe3e-7259-4bf4-860d-40ede11050b7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA\n","Training for 2000 epochs...\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 100/2000 [00:23<08:31,  3.72it/s]"]},{"output_type":"stream","name":"stdout","text":["[0m 23s (100 5%) 1.6169]\n","Whom Olar the blood\n","That your contleans of the at be the nerved let;\n","And sine, not son't the eath not  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 200/2000 [00:48<07:57,  3.77it/s]"]},{"output_type":"stream","name":"stdout","text":["[0m 48s (200 10%) 1.4490]\n","Whought,\n","Braken thee him actions, thou discore stames may from me,\n","Looks and for bope into enemy, and  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 300/2000 [01:12<07:14,  3.92it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 12s (300 15%) 1.3898]\n","Why way man;\n","And Raveration, and too throne?\n","\n","PRINCE ELIZABETH:\n","She answelly ston of this have attend  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 400/2000 [01:35<06:46,  3.93it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 35s (400 20%) 1.3627]\n","Why wife his thing dreed your honour.\n","\n","KING EDWARD IV:\n","Worthy lord, my knief, this saded every breathe \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 500/2000 [01:59<06:21,  3.93it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 59s (500 25%) 1.3864]\n","What with turns!\n","The pluck the prisoner than I have must whose realed the\n","commonier: but rebelling men \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 600/2000 [02:24<05:51,  3.98it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 24s (600 30%) 1.3426]\n","Where's to be a man.\n","And by beation be condity and\n","I have been prophet a traitors, such a week thy\n","dis \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 700/2000 [02:48<05:40,  3.82it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 48s (700 35%) 1.3140]\n","Whire troe's in your letters\n","With stefter my soul is exclassalaster how he hath\n","As on Henry and him to \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 800/2000 [03:12<05:09,  3.87it/s]"]},{"output_type":"stream","name":"stdout","text":["[3m 12s (800 40%) 1.3163]\n","Whire as my life and me,\n","And so you to the myself infect of an all,\n","Come conveyore the sun and in the  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 900/2000 [03:37<04:46,  3.85it/s]"]},{"output_type":"stream","name":"stdout","text":["[3m 37s (900 45%) 1.2978]\n","Whire order here;\n","And trust-pillions not with them; for who do\n","On such teft of rained end as you to do \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 1000/2000 [04:02<04:25,  3.77it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 2s (1000 50%) 1.3098]\n","Wherefore there lady;\n","What has a millops and the king as end\n","The poor war's subjects? the wepper bette \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 1100/2000 [04:26<04:15,  3.52it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 26s (1100 55%) 1.2825]\n","Whieve her, we would not have for a bough.\n","\n","GLOUCESTER:\n","The unserve a word in this bastards.\n","\n","PERDITA: \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 1200/2000 [04:51<03:26,  3.87it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 51s (1200 60%) 1.2897]\n","Whimself too can abuse as shall I be more\n","Can with them which any hutreads,\n","And many head for their co \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 1300/2000 [05:15<03:23,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["[5m 15s (1300 65%) 1.2926]\n","Whrifechieft ready well;\n","I know the way of your all set no put the heart\n","As a daggers.\n","\n","MENENIUS:\n","My l \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 1400/2000 [05:40<02:38,  3.78it/s]"]},{"output_type":"stream","name":"stdout","text":["[5m 40s (1400 70%) 1.2808]\n","Whiefled grown a speak speak.\n","\n","MENENIUS:\n","Why, sir, I cannot not had to the house.\n","\n","VIRGILIA:\n","I do more \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 1500/2000 [06:04<02:20,  3.55it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 4s (1500 75%) 1.2992]\n","Whate your pronounce thee hither,\n","Lovers of mine eyes with her of the commoning.\n","You may slaughters ar \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 1600/2000 [06:29<01:43,  3.88it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 29s (1600 80%) 1.2764]\n","Why, present lady-time,\n","Or out of hands with utter, my lord,\n","Of thy battle let the foul vows of flower \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 1700/2000 [06:53<01:16,  3.95it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 53s (1700 85%) 1.2734]\n","Whick thee byself.\n","\n","Boy:\n","Trust as if he hath littles were to kill'd a prince to him.\n","\n","DUKE VINCENTIO:\n"," \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 1800/2000 [07:17<00:51,  3.87it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 17s (1800 90%) 1.2644]\n","Why, Gaunt is a woman's blind fear,\n","Which makes an oaths to protect a deputy,\n","In privateous comfort th \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 1900/2000 [07:42<00:25,  3.96it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 42s (1900 95%) 1.3071]\n","Whose countrymen, and all, if the cords be gone.\n","\n","KING LEWIS XI:\n","Take it those much you and for my mea \n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [08:06<00:00,  4.11it/s]"]},{"output_type":"stream","name":"stdout","text":["[8m 6s (2000 100%) 1.2759]\n","Why forward, not there.\n","\n","HERMIONE:\n","He should rid him not stay my sight in the king;\n","You must come beho \n","\n","Saving...\n","Saved as shakespeare.pt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["final loss:\n","\n","`1.2759`\n","\n","Final generated sequence:\n","\n","`Why forward, not there.`\n","\n","`HERMIONE:\n","He should rid him not stay my sight in the king;\n","You must come beho`\n","\n","The final los is higher (but very close) when comapred to the previous model. Nevertheless, the generated sequences appear to have similar realism."],"metadata":{"id":"JqpdsCcqgHbF"}},{"cell_type":"markdown","source":["4) GRU RNN trained on dad jokes"],"metadata":{"id":"QHS5rTV6fss4"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import argparse\n","import os\n","\n","from tqdm import tqdm\n","\n","filename = '/content/drive/MyDrive/CS2516/Homework/jokes.txt'\n","model = 'gru'\n","n_epochs = 2000\n","print_every = 100\n","hidden_size = 128\n","n_layers = 2\n","learning_rate = 0.01\n","chunk_len = 200\n","batch_size = 128\n","shuffle = True\n","cuda = True\n","\n","if cuda:\n","    print(\"Using CUDA\")\n","\n","file, file_len, all_characters, n_characters = read_file(filename)\n","\n","def random_training_set(chunk_len, batch_size):\n","    inp = torch.LongTensor(batch_size, chunk_len)\n","    target = torch.LongTensor(batch_size, chunk_len)\n","    for bi in range(batch_size):\n","        start_index = random.randint(0, file_len - chunk_len - 1)\n","        end_index = start_index + chunk_len + 1\n","        chunk = file[start_index:end_index]\n","        inp[bi] = char_tensor(chunk[:-1], all_characters)\n","        target[bi] = char_tensor(chunk[1:], all_characters)\n","    inp = Variable(inp)\n","    target = Variable(target)\n","    if cuda:\n","        inp = inp.cuda()\n","        target = target.cuda()\n","    return inp, target\n","\n","def train(inp, target):\n","    \"\"\"\n","        inp: (batch_size, seq_size)\n","        target: (batch_size, seq_size)\n","    \"\"\"\n","    hidden = decoder.init_hidden(batch_size, cuda)\n","    decoder.zero_grad()\n","\n","    output, hidden = decoder(inp, hidden)\n","    loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n","\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.item()\n","\n","def save():\n","    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n","    torch.save((all_characters, decoder), save_filename)\n","    print('Saved as %s' % save_filename)\n","\n","# Initialize models and start training\n","\n","decoder = CharRNN(\n","    n_characters,\n","    hidden_size,\n","    n_characters,\n","    model=model,\n","    n_layers=n_layers,\n",")\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","if cuda:\n","    decoder.cuda()\n","\n","start = time.time()\n","all_losses = []\n","loss_avg = 0\n","\n","try:\n","    print(\"Training for %d epochs...\" % n_epochs)\n","    for epoch in tqdm(range(1, n_epochs + 1)):\n","        loss = train(*random_training_set(chunk_len, batch_size))\n","        loss_avg += loss\n","\n","        if epoch % print_every == 0:\n","            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","            print(generate(decoder, all_characters, 'Wh', 100, cuda=cuda), '\\n')\n","\n","    print(\"Saving...\")\n","    save()\n","\n","except KeyboardInterrupt:\n","    print(\"Saving before quit...\")\n","    save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zNA_Nycfyh2","executionInfo":{"status":"ok","timestamp":1698819438803,"user_tz":240,"elapsed":492300,"user":{"displayName":"João Dick","userId":"09906120919510529946"}},"outputId":"5bf391c8-517a-4e0a-bc0d-92afb4420031"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA\n","Training for 2000 epochs...\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 100/2000 [00:25<08:06,  3.91it/s]"]},{"output_type":"stream","name":"stdout","text":["[0m 24s (100 5%) 0.8921]\n","Whe was favorite no pression with a roman pizza tree?<> When he was the difference.\n","Have tay on the bo \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 200/2000 [00:50<07:42,  3.89it/s]"]},{"output_type":"stream","name":"stdout","text":["[0m 50s (200 10%) 0.1851]\n","Whatical fow do you go to read a batile?<>It was always so jaded.\n","Why did the coffee secroson?<> They' \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 300/2000 [01:14<07:14,  3.92it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 14s (300 15%) 0.1212]\n","What’s the drumman part of the car bey to tell you a fighting joke...<>but I forgot the punch line.\n","Wh \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 400/2000 [01:39<07:04,  3.77it/s]"]},{"output_type":"stream","name":"stdout","text":["[1m 39s (400 20%) 0.0986]\n","Whate a computer’s favorite snack?<>Microchips!\n","Why was the robot so tired after his road trip?<>He ha \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 500/2000 [02:04<06:35,  3.79it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 4s (500 25%) 0.0921]\n","Whe Shath his so popular?<>Because it has a lot of dates!\n","Why did Mickey Mouse take a trip into space? \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 600/2000 [02:28<06:03,  3.85it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 28s (600 30%) 0.0845]\n","Whating the other day teaching me how to read maps backwards<>turns out it was just spam.\n","I'm reading  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 700/2000 [02:52<05:34,  3.89it/s]"]},{"output_type":"stream","name":"stdout","text":["[2m 52s (700 35%) 0.0891]\n","When it called Cecor for?<>Because he couldn’t see that well.\n","My boss told me to have a good day...<>. \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 800/2000 [03:17<05:37,  3.56it/s]"]},{"output_type":"stream","name":"stdout","text":["[3m 17s (800 40%) 0.0761]\n","Whicken sedans!\n","How do you make a Kleenex dance? <>Put a little boogie in it!\n","A termite walks into a b \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 900/2000 [03:42<05:06,  3.59it/s]"]},{"output_type":"stream","name":"stdout","text":["[3m 42s (900 45%) 0.0831]\n","Who was lab partners with a door?<> When it's ajar.\n","I made a belt out of watches once...<> It was a wa \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 1000/2000 [04:06<04:18,  3.87it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 6s (1000 50%) 0.0800]\n","When it cross to soes? <> Sore arms.\n","Last night me and my girlfriend watched three Do jked only have t \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 1100/2000 [04:30<03:49,  3.93it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 30s (1100 55%) 0.0790]\n","Whis their wedding day?<>It was loaf at first sight.\n","Why do melons have weddings?<>Because they cantal \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 1200/2000 [04:55<03:29,  3.82it/s]"]},{"output_type":"stream","name":"stdout","text":["[4m 55s (1200 60%) 0.0745]\n","When it gets bad, I take something for it.\n","I used to be addicted to soap...<> but I'm clean now.\n","When  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 1300/2000 [05:20<03:10,  3.68it/s]"]},{"output_type":"stream","name":"stdout","text":["[5m 20s (1300 65%) 0.0907]\n","When it take to make an octopus laugh? <>Ten-tickles.\n","I’m only familiar with 25 letters in the English \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 1400/2000 [05:45<02:45,  3.63it/s]"]},{"output_type":"stream","name":"stdout","text":["[5m 45s (1400 70%) 0.0874]\n","When it's a nice gnawint to people eat beavers.\n","What’s the most patriotic states. <>I had to calm him  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 1500/2000 [06:10<02:16,  3.66it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 9s (1500 75%) 0.0778]\n","Whelcr ion.\n","Want to hear a joke about a piece of paper? Never mind... <>it's tearable.\n","I just watched  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 1600/2000 [06:34<01:43,  3.87it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 34s (1600 80%) 0.0733]\n","When it hit me.\n","I’ve been bored recently, so I decided to take up fencing.<> The neighbors keep demand \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 1700/2000 [06:58<01:17,  3.86it/s]"]},{"output_type":"stream","name":"stdout","text":["[6m 58s (1700 85%) 0.0751]\n","When it's ajar.\n","I made a belt out of watches once...<> It was a waist of time.\n","This furniture store ke \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 1800/2000 [07:23<00:52,  3.79it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 23s (1800 90%) 0.0742]\n","When it gets bad, I take something for it.\n","I used to be addicted to soap...<> but I'm clean now.\n","When  \n","\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 1900/2000 [07:47<00:26,  3.80it/s]"]},{"output_type":"stream","name":"stdout","text":["[7m 47s (1900 95%) 0.0727]\n","When it's ajar.\n","I made a belt out of watches once...<> It was a waist of time.\n","This furniture store ke \n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [08:11<00:00,  4.07it/s]"]},{"output_type":"stream","name":"stdout","text":["[8m 11s (2000 100%) 0.0767]\n","When it's ajar.\n","I made a belt out of watches once...<> It was a waist outates it saw the salad dressin \n","\n","Saving...\n","Saved as jokes.pt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["The achieved loss is lower than the model trained on Shakespeare.\n","\n","final loss:\n","\n","`0.0767`\n","\n","Final generated sequence:\n","\n","`When it's ajar.\n","I made a belt out of watches once...<> It was a waist outates it saw the salad dressin `"],"metadata":{"id":"QwArNY7bOajG"}}]}